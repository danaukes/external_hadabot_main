{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from read_data import read_world, read_sensor_data\n",
    "\n",
    "#add random seed for generating comparable pseudo random numbers\n",
    "np.random.seed(123)\n",
    "\n",
    "#plot preferences, interactive plotting mode\n",
    "plt.axis([-1, 12, 0, 10])\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "def plot_state(particles, landmarks, map_limits):\n",
    "    # Visualizes the state of the particle filter.\n",
    "    #\n",
    "    # Displays the particle cloud, mean position and landmarks.\n",
    "    \n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for particle in particles:\n",
    "        xs.append(particle['x'])\n",
    "        ys.append(particle['y'])\n",
    "\n",
    "    # landmark positions\n",
    "    lx=[]\n",
    "    ly=[]\n",
    "\n",
    "    for i in range (len(landmarks)):\n",
    "        lx.append(landmarks[i+1][0])\n",
    "        ly.append(landmarks[i+1][1])\n",
    "\n",
    "    # mean pose as current estimate\n",
    "    estimated_pose = mean_pose(particles)\n",
    "\n",
    "    # plot filter state\n",
    "    plt.clf()\n",
    "    plt.plot(xs, ys, 'r.')\n",
    "    plt.plot(lx, ly, 'bo',markersize=10)\n",
    "    plt.quiver(estimated_pose[0], estimated_pose[1], np.cos(estimated_pose[2]), np.sin(estimated_pose[2]), angles='xy',scale_units='xy')\n",
    "    plt.axis(map_limits)\n",
    "\n",
    "    plt.pause(0.01)\n",
    "\n",
    "def initialize_particles(num_particles, map_limits):\n",
    "    # randomly initialize the particles inside the map limits\n",
    "\n",
    "    particles = []\n",
    "\n",
    "    for i in range(num_particles):\n",
    "        particle = dict()\n",
    "\n",
    "        # draw x,y and theta coordinate from uniform distribution\n",
    "        # inside map limits\n",
    "        particle['x'] = np.random.uniform(map_limits[0], map_limits[1])\n",
    "        particle['y'] = np.random.uniform(map_limits[2], map_limits[3])\n",
    "        particle['theta'] = np.random.uniform(-np.pi, np.pi)\n",
    "\n",
    "        particles.append(particle)\n",
    "\n",
    "    return particles\n",
    "\n",
    "def mean_pose(particles):\n",
    "    # calculate the mean pose of a particle set.\n",
    "    #\n",
    "    # for x and y, the mean position is the mean of the particle coordinates\n",
    "    #\n",
    "    # for theta, we cannot simply average the angles because of the wraparound \n",
    "    # (jump from -pi to pi). Therefore, we generate unit vectors from the \n",
    "    # angles and calculate the angle of their average \n",
    "\n",
    "    # save x and y coordinates of particles\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    # save unit vectors corresponding to particle orientations \n",
    "    vxs_theta = []\n",
    "    vys_theta = []\n",
    "\n",
    "    for particle in particles:\n",
    "        xs.append(particle['x'])\n",
    "        ys.append(particle['y'])\n",
    "\n",
    "        #make unit vector from particle orientation\n",
    "        vxs_theta.append(np.cos(particle['theta']))\n",
    "        vys_theta.append(np.sin(particle['theta']))\n",
    "\n",
    "    #calculate average coordinates\n",
    "    mean_x = np.mean(xs)\n",
    "    mean_y = np.mean(ys)\n",
    "    mean_theta = np.arctan2(np.mean(vys_theta), np.mean(vxs_theta))\n",
    "\n",
    "    return [mean_x, mean_y, mean_theta]\n",
    "\n",
    "def sample_motion_model(odometry, particles):\n",
    "    # Samples new particle positions, based on old positions, the odometry\n",
    "    # measurements and the motion noise \n",
    "    # (probabilistic motion models slide 27)\n",
    "\n",
    "    delta_rot1 = odometry['r1']\n",
    "    delta_trans = odometry['t']\n",
    "    delta_rot2 = odometry['r2']\n",
    "\n",
    "    # the motion noise parameters: [alpha1, alpha2, alpha3, alpha4]\n",
    "    noise = [0.1, 0.1, 0.05, 0.05]\n",
    "\n",
    "    # generate new particle set after motion update\n",
    "    new_particles = []\n",
    "    \n",
    "    '''your code here'''\n",
    "    '''***        ***'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return new_particles\n",
    "\n",
    "def eval_sensor_model(sensor_data, particles, landmarks):\n",
    "    # Computes the observation likelihood of all particles, given the\n",
    "    # particle and landmark positions and sensor measurements\n",
    "    # (probabilistic sensor models slide 33)\n",
    "    #\n",
    "    # The employed sensor model is range only.\n",
    "\n",
    "    sigma_r = 0.2\n",
    "\n",
    "    #measured landmark ids and ranges\n",
    "    ids = sensor_data['id']\n",
    "    ranges = sensor_data['range']\n",
    "\n",
    "    weights = []\n",
    "    \n",
    "    '''your code here'''\n",
    "    '''***        ***'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #normalize weights\n",
    "    normalizer = sum(weights)\n",
    "    weights = weights / normalizer\n",
    "\n",
    "    return weights\n",
    "\n",
    "def resample_particles(particles, weights):\n",
    "    # Returns a new set of particles obtained by performing\n",
    "    # stochastic universal sampling, according to the particle weights.\n",
    "\n",
    "    new_particles = []\n",
    "\n",
    "    '''your code here'''\n",
    "    '''***        ***'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return new_particles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# implementation of a particle filter for robot pose estimation\n",
    "\n",
    "print \"Reading landmark positions\"\n",
    "landmarks = read_world(\"../data/world.dat\")\n",
    "\n",
    "print \"Reading sensor data\"\n",
    "sensor_readings = read_sensor_data(\"../data/sensor_data.dat\")\n",
    "\n",
    "#initialize the particles\n",
    "map_limits = [-1, 12, 0, 10]\n",
    "particles = initialize_particles(1000, map_limits)\n",
    "\n",
    "#run particle filter\n",
    "for timestep in range(len(sensor_readings)/2):\n",
    "\n",
    "    #plot the current state\n",
    "    plot_state(particles, landmarks, map_limits)\n",
    "\n",
    "    #predict particles by sampling from motion model with odometry info\n",
    "    new_particles = sample_motion_model(sensor_readings[timestep,'odometry'], particles)\n",
    "\n",
    "    #calculate importance weights according to sensor model\n",
    "    weights = eval_sensor_model(sensor_readings[timestep, 'sensor'], new_particles, landmarks)\n",
    "\n",
    "    #resample new particle set according to their importance weights\n",
    "    particles = resample_particles(new_particles, weights)\n",
    "\n",
    "plt.show('hold')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}